{
  "_args": [
    [
      {
        "raw": "css-tokenize@^1.0.1",
        "scope": null,
        "escapedName": "css-tokenize",
        "name": "css-tokenize",
        "rawSpec": "^1.0.1",
        "spec": ">=1.0.1 <2.0.0",
        "type": "range"
      },
      "/Users/pasqualevitiello/My Folder/Job/Projects/Gits/system-studio-landing/node_modules/css-rule-stream"
    ]
  ],
  "_from": "css-tokenize@>=1.0.1 <2.0.0",
  "_id": "css-tokenize@1.0.1",
  "_inCache": true,
  "_location": "/css-tokenize",
  "_nodeVersion": "0.11.14",
  "_npmUser": {
    "name": "anandthakker",
    "email": "vestibule@anandthakker.net"
  },
  "_npmVersion": "2.1.8",
  "_phantomChildren": {
    "core-util-is": "1.0.2",
    "inherits": "2.0.3"
  },
  "_requested": {
    "raw": "css-tokenize@^1.0.1",
    "scope": null,
    "escapedName": "css-tokenize",
    "name": "css-tokenize",
    "rawSpec": "^1.0.1",
    "spec": ">=1.0.1 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/css-rule-stream"
  ],
  "_resolved": "https://registry.npmjs.org/css-tokenize/-/css-tokenize-1.0.1.tgz",
  "_shasum": "4625cb1eda21c143858b7f81d6803c1d26fc14be",
  "_shrinkwrap": null,
  "_spec": "css-tokenize@^1.0.1",
  "_where": "/Users/pasqualevitiello/My Folder/Job/Projects/Gits/system-studio-landing/node_modules/css-rule-stream",
  "author": {
    "name": "Anand Thakker",
    "email": "vestibule@anandthakker.net",
    "url": "http://anandthakker.net"
  },
  "bugs": {
    "url": "https://github.com/anandthakker/css-tokenize/issues"
  },
  "dependencies": {
    "inherits": "^2.0.1",
    "readable-stream": "^1.0.33"
  },
  "description": "Transform stream that tokenizes CSS",
  "devDependencies": {
    "tape": "^3.0.3",
    "through2": "^0.6.3"
  },
  "directories": {},
  "dist": {
    "shasum": "4625cb1eda21c143858b7f81d6803c1d26fc14be",
    "tarball": "https://registry.npmjs.org/css-tokenize/-/css-tokenize-1.0.1.tgz"
  },
  "gitHead": "d4acf6d2010cbbb61f69817f53b249471468d7a9",
  "homepage": "https://github.com/anandthakker/css-tokenize",
  "keywords": [
    "css",
    "tokenize",
    "parse",
    "stream",
    "streaming"
  ],
  "license": "MIT",
  "main": "index.js",
  "maintainers": [
    {
      "name": "anandthakker",
      "email": "vestibule@anandthakker.net"
    }
  ],
  "name": "css-tokenize",
  "optionalDependencies": {},
  "readme": "css-tokenize\n============\n\nCoarsely tokenize a stream of CSS, largely modeled after \n[substack/html-tokenize](/substack/html-tokenize).\n\n```javascript\nvar tokenize = require('css-tokenize'),\nthrough = require('through2');\n\nprocess.stdin\n.pipe(tokenize())\n.pipe(through.obj(function(token, enc, next) {\n  token[1] = token[1].toString(); // it's a buffer slice\n  console.log('TOKEN', token);\n  next();\n}))\n```\n\nInput:\n```css\n\ndiv {\n  background: red;\n}\n\n.cls {\n  color: green;\n}\n\n#id {\n  font-size: 10px;\n}\n\n/* comment */\n\n@media screen and (min-width: 1000px) {\n  a {\n    text-decoration: underline;\n  }\n}\n\na:hover {\n  font-weight: bold;  \n}\n\nsection \n\n\n{\n  margin: 0;\n  /* comment wthin a rule */\n  padding: 5px;\n}\n\n\nbody > * {\n  \n}\n```\n\nOutput:\n```\nTOKEN [ 'root', '\\n' ]\nTOKEN [ 'rule_start', 'div {' ]\nTOKEN [ 'rule', '\\n  background: red;\\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'root', '\\n\\n' ]\nTOKEN [ 'rule_start', '.cls {' ]\nTOKEN [ 'rule', '\\n  color: green;\\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'root', '\\n\\n' ]\nTOKEN [ 'rule_start', '#id {' ]\nTOKEN [ 'rule', '\\n  font-size: 10px;\\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'comment', '\\n\\n/* comment */' ]\nTOKEN [ 'space', '\\n\\n' ]\nTOKEN [ 'atrule_start', '@media screen and (min-width: 1000px) {' ]\nTOKEN [ 'atrule', '\\n  ' ]\nTOKEN [ 'rule_start', 'a {' ]\nTOKEN [ 'rule', '\\n    text-decoration: underline;\\n  ' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'atrule', '\\n' ]\nTOKEN [ 'atrule_end', '}' ]\nTOKEN [ 'root', '\\n\\n' ]\nTOKEN [ 'rule_start', 'a:hover {' ]\nTOKEN [ 'rule', '\\n  font-weight: bold;  \\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'root', '\\n\\n' ]\nTOKEN [ 'rule_start', 'section \\n\\n\\n{' ]\nTOKEN [ 'rule', '\\n  margin: 0;\\n  ' ]\nTOKEN [ 'comment', '/* comment wthin a rule */' ]\nTOKEN [ 'rule', '\\n  padding: 5px;\\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'root', '\\n\\n\\n' ]\nTOKEN [ 'rule_start', 'body > * {' ]\nTOKEN [ 'rule', '\\n  \\n' ]\nTOKEN [ 'rule_end', '}' ]\nTOKEN [ 'root', '\\n' ]\n```\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/anandthakker/css-tokenize.git"
  },
  "scripts": {
    "test": "tape test/*.js"
  },
  "version": "1.0.1"
}
